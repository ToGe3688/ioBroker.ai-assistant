{
    "A descriptive name for your function": "Описательное имя для вашей функции",
    "API Token": "API-токен",
    "API Token for Inference Server": "Токен API для сервера вывода",
    "Active": "Активный",
    "Ask": "Спросить",
    "Assistant Settings": "Настройки Ассистента",
    "Assistant can use Object": "Ассистент может использовать объект",
    "Assistant can use this function": "Ассистент может использовать эту функцию",
    "Custom functions for assistant": "Пользовательские функции для помощника",
    "Datapoint (Request)": "Точка данных (запрос)",
    "Datapoint (Result)": "Точка данных (результат)",
    "Debug / Chain-of-Thought Output": "Отладка/вывод цепочки мыслей",
    "Define custom functions for the assistant. Make sure to add a good description for your functions so the assistant knows when to call your function. Each function needs a datapoint that starts the process and another datapoint that contains the result of your function.": "Определите пользовательские функции для помощника. Обязательно добавьте хорошее описание своих функций, чтобы помощник знал, когда вызывать вашу функцию. Каждой функции нужна точка данных, которая запускает процесс, и другая точка данных, содержащая результат вашей функции.",
    "Describe the personality of your assistant": "Опишите личность вашего помощника",
    "Describe what your function does and how the data for the request should look. This is important for the assistant to understand your function.": "Опишите, что делает ваша функция и как должны выглядеть данные для запроса. Это важно, чтобы помощник понял ваши функции.",
    "Description": "Описание",
    "Do you really want to import objects from enum.rooms? Existing objects will be reset!": "Вы действительно хотите импортировать объекты из enum.rooms? Существующие объекты будут сброшены!",
    "ERROR: column 'Model' must contain unique text": "ОШИБКА: столбец «Модель» должен содержать уникальный текст.",
    "English": "Английский",
    "Friendly and helpful": "Дружелюбный и услужливый",
    "Functions": "Функции",
    "German": "немецкий",
    "Give your personal assistant a name and describe its personality. Choose a model that should be used for your assistant.": "Дайте своему личному помощнику имя и опишите его личность. Выберите модель, которую следует использовать для вашего помощника.",
    "How long to wait between retries": "Как долго ждать между повторными попытками",
    "How many times should we retry if request to model fails": "Сколько раз мы должны повторить попытку, если запрос на моделирование не удался",
    "If greater 0 previous messages will be included in the request so the tool will stay in context": "Если в запрос будет включено больше 0 предыдущих сообщений, инструмент останется в контексте.",
    "Import objects from enum.rooms": "Импортировать объекты из enum.rooms",
    "Language": "Язык",
    "Last answer": "Последний ответ",
    "Limit the response of the tool to your desired amount of tokens.": "Ограничьте реакцию инструмента желаемым количеством токенов.",
    "Link to LM Studio": "Ссылка на студию LM",
    "Link to LocalAI": "Ссылка на LocalAI",
    "Max. Retries": "Макс. Повторные попытки",
    "Max. Tokens": "Макс. Токены",
    "Message History (Chat Mode)": "История сообщений (режим чата)",
    "Model": "Модель",
    "Model Settings": "Настройки модели",
    "Model is active": "Модель активна",
    "Models": "Модели",
    "Name": "Имя",
    "Name for the Assistant": "Имя помощника",
    "Name of the Model": "Название модели",
    "Object": "Объект",
    "Object access for assistant": "Доступ к объекту для помощника",
    "Objects": "Объекты",
    "Personality": "Личность",
    "Please add the objects you want to use with the assistant. The assistant will be able to read and control these objects. You can use the button to import all states from your configured room sorting. Make sure to only include needed states to save tokens.": "Добавьте объекты, которые хотите использовать, с помощью помощника. Помощник сможет читать и управлять этими объектами. Вы можете использовать кнопку, чтобы импортировать все состояния из настроенной вами сортировки комнат. Обязательно включите только необходимые состояния для сохранения токенов.",
    "Please enter your Anthropic API Token to start using models like Opus, Haiku and Sonnet. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Введите свой токен Anthropic API, чтобы начать использовать такие модели, как Opus, Haiku и Sonnet. Если выпущены новые модели, вы можете просто добавить их в таблицу, чтобы начать использовать их с помощниками искусственного интеллекта.",
    "Please enter your Deepseek API Token to start using the models. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Пожалуйста, введите свой токен DeepSeek API, чтобы начать использовать модели. Если выпущены новые модели, вы можете просто добавить их в таблицу, чтобы начать использовать их с помощниками искусственного интеллекта.",
    "Please enter your OpenAI API Token to start using models like Gpt4, Gpt4-o1, Gpt3-5. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Введите свой токен API OpenAI, чтобы начать использовать такие модели, как Gpt4, Gpt4-o1, Gpt3-5. Если выпущены новые модели, вы можете просто добавить их в таблицу, чтобы начать использовать их с помощниками искусственного интеллекта.",
    "Please enter your Openrouter API Token to start using the models. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Введите свой токен API Openrouter, чтобы начать использовать модели. Если выпущены новые модели, вы можете просто добавить их в таблицу, чтобы начать использовать их с помощниками искусственного интеллекта.",
    "Please enter your Perplexity API Token to start using the models. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Введите свой токен Perplexity API, чтобы начать использовать модели. Если выпущены новые модели, вы можете просто добавить их в таблицу, чтобы начать использовать их с помощниками искусственного интеллекта.",
    "Question": "Вопрос",
    "Request Settings": "Запросить настройки",
    "Retry Delay": "Задержка повтора",
    "Room or sorting for Object": "Комната или сортировка объекта",
    "Save the configuration first": "Чтобы протестировать помощника, сначала убедитесь, что вы сохранили конфигурацию.",
    "Select how many messages should be included for context retention. Temperature defines creativity/randomness of output from 0-1 where 0 is the most predictable output. Set how many tokens should be generated max for assistant responses.": "Выберите, сколько сообщений должно быть включено для сохранения контекста. Температура определяет креативность/случайность результата от 0 до 1, где 0 — наиболее предсказуемый результат. Установите максимальное количество токенов, которое должно быть сгенерировано для ответов помощника.",
    "Select if failed requests to the assistant should be retried and how long to wait between tries.": "Выберите, следует ли повторять неудачные запросы к помощнику и как долго ждать между попытками.",
    "Select the language that should be used by the assistant": "Выберите язык, который будет использовать помощник",
    "Setting for creativity/consistency of the models response. (Leave at default if you are not sure!=": "Настройка креативности/последовательности ответов моделей. (Если вы не уверены, оставьте значение по умолчанию!=",
    "Settings": "Настройки",
    "Sort": "Сортировать",
    "Temperature": "Температура",
    "The datapoint that contains the result of your function call (Has to be fulfilled in 60 Seconds!)": "Точка данных, содержащая результат вызова функции (должна быть выполнена за 60 секунд!)",
    "The datapoint that starts the request for the function": "Точка данных, которая запускает запрос функции",
    "URL for Inference Server": "URL-адрес сервера вывода",
    "When activated the internal thought process of the assistant will be written to the response datapoint": "При активации внутренний мыслительный процесс помощника будет записан в точку данных ответа.",
    "Which Model should be used": "Какую модель следует использовать",
    "You can use your custom or self hosted inference server to run open source models. The server needs to follow the rest api standards used by many providers, see examples below. Please make sure to add your used models by name to the table below.": "Вы можете использовать собственный или собственный сервер вывода для запуска моделей с открытым исходным кодом. Сервер должен соответствовать остальным стандартам API, используемым многими провайдерами, см. примеры ниже. Обязательно добавьте подержанные модели в таблицу ниже."
}