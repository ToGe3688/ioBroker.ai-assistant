{
    "A descriptive name for your function": "Un nombre descriptivo para su función.",
    "API Token": "Ficha API",
    "API Token for Inference Server": "Token API para servidor de inferencia",
    "Active": "Activo",
    "Ask": "Preguntar",
    "Assistant Settings": "Configuración del asistente",
    "Assistant can use Object": "El asistente puede usar el objeto",
    "Assistant can use this function": "El asistente puede usar esta función",
    "Custom functions for assistant": "Funciones personalizadas para asistente",
    "Datapoint (Request)": "Punto de datos (Solicitud)",
    "Datapoint (Result)": "Punto de datos (resultado)",
    "Debug / Chain-of-Thought Output": "Salida de depuración/cadena de pensamiento",
    "Define custom functions for the assistant. Make sure to add a good description for your functions so the assistant knows when to call your function. Each function needs a datapoint that starts the process and another datapoint that contains the result of your function.": "Definir funciones personalizadas para el asistente. Asegúrese de agregar una buena descripción de sus funciones para que el asistente sepa cuándo llamar a su función. Cada función necesita un punto de datos que inicie el proceso y otro punto de datos que contenga el resultado de su función.",
    "Describe the personality of your assistant": "Describe la personalidad de tu asistente.",
    "Describe what your function does and how the data for the request should look. This is important for the assistant to understand your function.": "Describe qué hace tu función y cómo deben verse los datos de la solicitud. Esto es importante para que el asistente comprenda su función.",
    "Description": "Descripción",
    "Do you really want to import objects from enum.rooms? Existing objects will be reset!": "¿Realmente quieres importar objetos desde enum.rooms? ¡Los objetos existentes se restablecerán!",
    "ERROR: column 'Model' must contain unique text": "ERROR: la columna 'Modelo' debe contener texto único",
    "English": "Inglés",
    "Friendly and helpful": "Amable y servicial",
    "Functions": "Funciones",
    "German": "Alemán",
    "Give your personal assistant a name and describe its personality. Choose a model that should be used for your assistant.": "Dale un nombre a tu asistente personal y describe su personalidad. Elija un modelo que deba usarse para su asistente.",
    "How long to wait between retries": "¿Cuánto tiempo esperar entre reintentos?",
    "How many times should we retry if request to model fails": "¿Cuántas veces debemos volver a intentarlo si falla la solicitud de modelo?",
    "If greater 0 previous messages will be included in the request so the tool will stay in context": "Si es mayor, se incluirán 0 mensajes anteriores en la solicitud para que la herramienta permanezca en contexto",
    "Import objects from enum.rooms": "Importar objetos desde enum.rooms",
    "Language": "Idioma",
    "Last answer": "Última respuesta",
    "Limit the response of the tool to your desired amount of tokens.": "Limite la respuesta de la herramienta a la cantidad deseada de tokens.",
    "Link to LM Studio": "Enlace a LM Estudio",
    "Link to LocalAI": "Enlace a LocalAI",
    "Max. Retries": "Máx. Reintentos",
    "Max. Tokens": "Máx. Fichas",
    "Message History (Chat Mode)": "Historial de mensajes (modo chat)",
    "Model": "Modelo",
    "Model Settings": "Configuración del modelo",
    "Model is active": "El modelo está activo.",
    "Models": "Modelos",
    "Name": "Nombre",
    "Name for the Assistant": "Nombre del asistente",
    "Name of the Model": "Nombre del modelo",
    "Object": "Objeto",
    "Object access for assistant": "Acceso a objetos para asistente",
    "Objects": "Objetos",
    "Personality": "Personalidad",
    "Please add the objects you want to use with the assistant. The assistant will be able to read and control these objects. You can use the button to import all states from your configured room sorting. Make sure to only include needed states to save tokens.": "Agregue los objetos que desea usar con el asistente. El asistente podrá leer y controlar estos objetos. Puede utilizar el botón para importar todos los estados desde la clasificación de habitaciones configurada. Asegúrese de incluir solo los estados necesarios para guardar tokens.",
    "Please enter your Anthropic API Token to start using models like Opus, Haiku and Sonnet. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Ingrese su token API Anthropic para comenzar a usar modelos como Opus, Haiku y Sonnet. Si se lanzan nuevos modelos, simplemente puede agregarlos en la tabla para comenzar a usarlos con asistentes de inteligencia artificial.",
    "Please enter your Deepseek API Token to start using the models. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Ingrese su token API Deepseek para comenzar a usar los modelos. Si hay nuevos modelos lanzados, simplemente puede agregarlos a la mesa para comenzar a usarlos con asistentes de IA.",
    "Please enter your OpenAI API Token to start using models like Gpt4, Gpt4-o1, Gpt3-5. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Ingrese su token API de OpenAI para comenzar a usar modelos como Gpt4, Gpt4-o1, Gpt3-5. Si se lanzan nuevos modelos, simplemente puede agregarlos en la tabla para comenzar a usarlos con asistentes de inteligencia artificial.",
    "Please enter your Openrouter API Token to start using the models. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Ingrese su token API de Openrouter para comenzar a usar los modelos. Si se lanzan nuevos modelos, simplemente puede agregarlos en la tabla para comenzar a usarlos con asistentes de inteligencia artificial.",
    "Please enter your Perplexity API Token to start using the models. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Ingrese su token API de Perplexity para comenzar a usar los modelos. Si se lanzan nuevos modelos, simplemente puede agregarlos en la tabla para comenzar a usarlos con asistentes de inteligencia artificial.",
    "Question": "Pregunta",
    "Request Settings": "Solicitar configuración",
    "Retry Delay": "Retardo de reintento",
    "Room or sorting for Object": "Habitación o clasificación por objeto",
    "Save the configuration first": "Para probar el asistente, primero asegúrese de haber guardado la configuración",
    "Select how many messages should be included for context retention. Temperature defines creativity/randomness of output from 0-1 where 0 is the most predictable output. Set how many tokens should be generated max for assistant responses.": "Seleccione cuántos mensajes se deben incluir para la retención de contexto. La temperatura define la creatividad/aleatoriedad del resultado de 0 a 1, donde 0 es el resultado más predecible. Establezca cuántos tokens se deben generar como máximo para las respuestas del asistente.",
    "Select if failed requests to the assistant should be retried and how long to wait between tries.": "Seleccione si se deben volver a intentar las solicitudes fallidas al asistente y cuánto tiempo esperar entre intentos.",
    "Select the language that should be used by the assistant": "Seleccione el idioma que debe utilizar el asistente",
    "Setting for creativity/consistency of the models response. (Leave at default if you are not sure!=": "Ajuste para la creatividad/consistencia de la respuesta del modelo. (¡Déjelo como predeterminado si no está seguro!=",
    "Settings": "Ajustes",
    "Sort": "Clasificar",
    "Temperature": "Temperatura",
    "The datapoint that contains the result of your function call (Has to be fulfilled in 60 Seconds!)": "El punto de datos que contiene el resultado de su llamada a función (¡debe cumplirse en 60 segundos!)",
    "The datapoint that starts the request for the function": "El punto de datos que inicia la solicitud de la función.",
    "URL for Inference Server": "URL para el servidor de inferencia",
    "When activated the internal thought process of the assistant will be written to the response datapoint": "Cuando se activa, el proceso de pensamiento interno del asistente se escribirá en el punto de datos de respuesta.",
    "Which Model should be used": "¿Qué modelo se debe utilizar?",
    "You can use your custom or self hosted inference server to run open source models. The server needs to follow the rest api standards used by many providers, see examples below. Please make sure to add your used models by name to the table below.": "Puede utilizar su servidor de inferencia personalizado o autohospedado para ejecutar modelos de código abierto. El servidor debe seguir el resto de los estándares API utilizados por muchos proveedores; consulte los ejemplos a continuación. Asegúrese de agregar sus modelos usados ​​por nombre a la siguiente tabla."
}