{
	"Assistant Settings": "Assistenten-Einstellungen",
	"Give your personal assistant a name and describe its personality. Choose a model that should be used for your assistant.": "Geben Sie Ihrem persönlichen Assistenten einen Namen und beschreiben Sie seine Persönlichkeit. Wählen Sie ein Modell aus, das für Ihren Assistenten verwendet werden soll.",
	"Name": "Name",
	"Name for the Assistant": "Name für den Assistenten",
	"Model": "Modell",
	"Which Model should be used": "Welches Modell soll verwendet werden",
	"Personality": "Persönlichkeit",
	"Describe the personality of your assistant": "Beschreiben Sie die Persönlichkeit Ihres Assistenten",
	"Friendly and helpful": "Freundlich und hilfsbereit",
	"Language": "Sprache",
	"Select the language that should be used by the assistant": "Wählen Sie die Sprache aus, die der Assistent verwenden soll",
	"English": "Englisch",
	"German": "Deutsch",
	"Debug / Chain-of-Thought Output": "Debug / Gedankengang-Ausgabe",
	"When activated the internal thought process of the assistant will be written to the response datapoint": "Wenn aktiviert, wird der interne Gedankenprozess des Assistenten in den Antwort-Datenpunkt geschrieben",
	"Model Settings": "Modell-Einstellungen",
	"Select how many messages should be included for context retention. Temperature defines creativity/randomness of output from 0-1 where 0 is the most predictable output. Set how many tokens should be generated max for assistant responses.": "Wählen Sie aus, wie viele Nachrichten für die Kontextbeibehaltung einbezogen werden sollen. Temperature definiert die Kreativität/Zufälligkeit der Ausgabe von 0-1, wobei 0 die vorhersehbarste Ausgabe ist. Legen Sie fest, wie viele Tokens maximal für Assistenten-Antworten generiert werden sollen.",
	"Message History (Chat Mode)": "Nachrichtenverlauf (Chat-Modus)",
	"If greater 0 previous messages will be included in the request so the tool will stay in context": "Bei Werten größer 0 werden vorherige Nachrichten in die Anfrage einbezogen, damit das Tool im Kontext bleibt",
	"Temperature": "Temperature",
	"Setting for creativity/consistency of the models response. (Leave at default if you are not sure!=": "Einstellung für Kreativität/Konsistenz der Modellantwort. (Bei Unsicherheit auf Standardwert belassen!=",
	"Max. Tokens": "Max. Tokens",
	"Limit the response of the tool to your desired amount of tokens.": "Begrenzen Sie die Antwort des Tools auf die gewünschte Anzahl von Tokens.",
	"Request Settings": "Anfrage-Einstellungen",
	"Select if failed requests to the assistant should be retried and how long to wait between tries.": "Wählen Sie aus, ob fehlgeschlagene Anfragen an den Assistenten wiederholt werden sollen und wie lange zwischen den Versuchen gewartet werden soll.",
	"Max. Retries": "Max. Wiederholungen",
	"How many times should we retry if request to model fails": "Wie oft soll bei fehlgeschlagener Modellanfrage wiederholt werden",
	"Retry Delay": "Wiederholungsverzögerung",
	"How long to wait between retries": "Wie lange zwischen Wiederholungen gewartet werden soll",
	"Object access for assistant": "Objektzugriff für Assistenten",
	"Please add the objects you want to use with the assistant. The assistant will be able to read and control these objects. You can use the button to import all states from your configured room sorting. Make sure to only include needed states to save tokens.": "Bitte fügen Sie die Objekte hinzu, die Sie mit dem Assistenten verwenden möchten. Der Assistent wird diese Objekte lesen und steuern können. Sie können den Button verwenden, um alle Zustände aus Ihrer konfigurierten Raumsortierung zu importieren. Stellen Sie sicher, dass Sie nur benötigte Zustände einbeziehen, um Tokens zu sparen.",
	"Import objects from enum.rooms": "Objekte aus enum.rooms importieren",
	"Do you really want to import objects from enum.rooms? Existing objects will be reset!": "Möchten Sie wirklich Objekte aus enum.rooms importieren? Bestehende Objekte werden zurückgesetzt!",
	"Objects": "Objekte",
	"Active": "Aktiv",
	"Assistant can use Object": "Assistent kann Objekt verwenden",
	"Sort": "Sortierung",
	"Room or sorting for Object": "Raum oder Sortierung für Objekt",
	"Object": "Objekt",
	"Custom functions for assistant": "Benutzerdefinierte Funktionen für Assistenten",
	"Define custom functions for the assistant. Make sure to add a good description for your functions so the assistant knows when to call your function. Each function needs a datapoint that starts the process and another datapoint that contains the result of your function.": "Definieren Sie benutzerdefinierte Funktionen für den Assistenten. Fügen Sie eine gute Beschreibung für Ihre Funktionen hinzu, damit der Assistent weiß, wann er Ihre Funktion aufrufen soll. Jede Funktion benötigt einen Datenpunkt, der den Prozess startet, und einen weiteren Datenpunkt, der das Ergebnis Ihrer Funktion enthält.",
	"Functions": "Funktionen",
	"Assistant can use this function": "Assistent kann diese Funktion verwenden",
	"A descriptive name for your function": "Ein beschreibender Name für Ihre Funktion",
	"Description": "Beschreibung",
	"Describe what your function does and how the data for the request should look. This is important for the assistant to understand your function.": "Beschreiben Sie, was Ihre Funktion macht und wie die Daten für die Anfrage aussehen sollen. Dies ist wichtig, damit der Assistent Ihre Funktion versteht.",
	"Datapoint (Request)": "Datenpunkt (Anfrage)",
	"The datapoint that starts the request for the function": "Der Datenpunkt, der die Anfrage für die Funktion startet",
	"Datapoint (Result)": "Datenpunkt (Ergebnis)",
	"The datapoint that contains the result of your function call (Has to be fulfilled in 60 Seconds!)": "Der Datenpunkt, der das Ergebnis Ihres Funktionsaufrufs enthält (Muss innerhalb von 60 Sekunden erfüllt werden!)",
	"Please enter your Anthropic API Token to start using models like Opus, Haiku and Sonnet. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Bitte geben Sie Ihren Anthropic API-Token ein, um Modelle wie Opus, Haiku und Sonnet zu nutzen. Wenn neue Modelle veröffentlicht werden, können Sie diese einfach in der Tabelle hinzufügen, um sie mit KI-Assistenten zu verwenden.",
	"Settings": "Einstellungen",
	"API Token": "API-Token",
	"ERROR: column 'Model' must contain unique text": "FEHLER: Spalte 'Modell' muss eindeutigen Text enthalten",
	"Models": "Modelle",
	"Model is active": "Modell ist aktiv",
	"Name of the Model": "Name des Modells",
	"Please enter your OpenAI API Token to start using models like Gpt4, Gpt4-o1, Gpt3-5. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Bitte geben Sie Ihren OpenAI API-Token ein, um Modelle wie Gpt4, Gpt4-o1, Gpt3-5 zu nutzen. Wenn neue Modelle veröffentlicht werden, können Sie diese einfach in der Tabelle hinzufügen, um sie mit KI-Assistenten zu verwenden.",
	"Please enter your Perplexity API Token to start using the models. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Bitte geben Sie Ihren Perplexity API-Token ein, um die Modelle zu nutzen. Wenn neue Modelle veröffentlicht werden, können Sie diese einfach in der Tabelle hinzufügen, um sie mit KI-Assistenten zu verwenden.",
	"Please enter your Openrouter API Token to start using the models. If there are new models released you can simply add them in the table to start using them with ai assistants.": "Bitte geben Sie Ihren Openrouter API-Token ein, um die Modelle zu nutzen. Wenn neue Modelle veröffentlicht werden, können Sie diese einfach in der Tabelle hinzufügen, um sie mit KI-Assistenten zu verwenden.",
	"You can use your custom or self hosted inference server to run open source models. The server needs to follow the rest api standards used by many providers, see examples below. Please make sure to add your used models by name to the table below.": "Sie können Ihren benutzerdefinierten oder selbst gehosteten Inference-Server verwenden, um Open-Source-Modelle auszuführen. Der Server muss den REST-API-Standards folgen, die von vielen Anbietern verwendet werden, siehe Beispiele unten. Bitte stellen Sie sicher, dass Sie Ihre verwendeten Modelle mit Namen in die untenstehende Tabelle einfügen.",
	"Link to LM Studio": "Link zu LM Studio",
	"Link to LocalAI": "Link zu LocalAI",
	"URL for Inference Server": "URL für Inference-Server",
	"API Token for Inference Server": "API-Token für Inference-Server"
}